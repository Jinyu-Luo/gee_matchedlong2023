---
title: "Modeling Longitudinal Binary Outcomes in a Small Matched-Pair Sample with Application to Cardiovascular Data: A Simulation Study"
format:
  aft-pdf:
    keep-tex: true  
  aft-html: default
number-sections: true
author:
  - name: Jinyu Luo
    affiliations:
      - name: University of Toronto
        department: Biostatistics
        address: 155 College Street
        city: Toronto
        country: Canada
        postal-code: M5T 1P8
    orcid: 0009-0004-1101-7040
    email: jinyu.luo@mail.utoronto.ca
  - name: Chun-Po Steve Fan 
    affiliations:
      - name: University Health Network
        department: Analytic lead at Rogers Computational Program
        address: 585 University Ave
        city: Toronto
        country: Canada
        postal-code: M5G 2N2
    orcid: 0000-0002-6373-0532
    email: steve.fan@uhn.ca
  - name: Sudipta Saha 
    affiliations:
      - name: University Health Network
        department: Analytic lead at Rogers Computational Program
        address: 585 University Ave
        city: Toronto
        country: Canada
        postal-code: M5G 2N2
    email: Sudipta.Saha@uhn.ca
  - name: Aya Mitani
    affiliations:
      - name: University of Toronto
        department: Biostatistics
        address: 155 College Street
        city: Toronto
        country: Canada
        postal-code: M5T 1P8
    orcid: 0000-0002-0373-5032
    email: aya.mitani@utoronto.ca

abstract: |
  This study aimed to address the challenge of modeling small sample matched-pair longitudinal data in cardiovascular research. The independent working correlation structure in Generalized Estimating Equations (GEE), a robust method widely used for modeling endogenous follow-up data, relies on large-sample theory. Prior research has noted significant constraints due to small sample sizes for continuous outcomes. We evaluated the performance and validity of the GEE method and the two-stage quasi-least squares (QLS) approach in analyzing small matched-pair longitudinal binary data, particularly focusing on the interaction effect between bicuspid aortic valve (BAV) and time on aortic root size post-surgery. Hospital cohorts with longitudinal outcomes across two exposure groups were matched using propensity scores based on baseline characteristics to eliminate potential confounding effects, which is followed by GEE fit assuming that working correlation structure is AR1 to get a set of regression coefficients for simulation parameters. Simulations were designed to mimic real-world dropout processes, where previous survival outcomes and associated covariates influence longitudinal outcomes. Standard errors were adjusted by degrees of freedom to prevent underestimation by the sandwich estimator. Results: The QLS method demonstrated superior performance, with mean estimates closer to the true coefficients and narrower confidence intervals than GEE, while GEE provided more accurate estimation for the interaction effect but exhibited higher variability in estimates. Both methods struggled to capture the effect of time. Including confounding covariates did not significantly impact performance. QLS provided more consistent estimates across different correlation structures but with higher bias. Conclusion: Proper specification of the correlation structure is crucial for the robust analysis of small sample longitudinal data. For studies with small sample sizes and complex correlation structures, QLS may offer a more reliable alternative by providing consistent estimates with lower variability. These findings underscore the importance of methodological considerations in longitudinal data analysis and offer guidance for selecting appropriate analytical approaches.
keywords: [GEE, QLS, longitudinal]
reference-section-title: References
bibliography: bibliography.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


## Introduction {#sec-intro}

The generalized estimating equations (GEE) method is commonly used in longitudinal studies where the response variable for each subject is measured repeatedly over time [@LiangZeger1986]. It is an extension of the quasi-likelihood method that models the marginal expectation of the response, either discrete or binary, as a function of a set of explanatory variables [@Agresti2nd]. Instead of assuming a particular type of distribution for the outcome $Y$, each marginal mean is linked to a linear predictor and educated guess for the variance-covariance structure, which accounts for the temporal correlation among repeated measurements. Since there is no need to specify the random effects for individual subjects or clusters, GEE provides an average response in the population rather than individual-specific effects. 

Our motivation stems from the work which assessed the natural history of the aortic root in patients with bicuspid versus tricuspid aortic valves (BAVs vs. TAVs) after replacement of the aortic valve and ascending aorta at the Peter Munk Cardiac Center [@Hui2018]. The aorta is the main artery that carries blood from the heart's left ventricle to the rest of the human body. According to the 2014 ESC guidelines on diagnosing and treating aortic diseases, aorta dilatation is a clinical condition with aorta diameter greater than 40 mm, irrespective of body surface area. It is commonly present in patients with BAV, a congenital heart defect when the aortic valve has only two leaflets instead of three and affects approximately 1-2% of the general population [@Wang2021]. Patients with aortic diameter exceeding 4.5 mm are usually associated with ascending aortic events. Evidence showed that the dilation of aortic root cannot be suppressed even after AVR [@Bruce2003]. Still, other researchers found that the ascending aorta dilatation rate was similar between the BAV and TAV post-surgery [@KIM202053]. 

Given that BAV is a congenital cardiac abnormality, conducting randomized controlled trials is not feasible. Researchers often pair BAV patients with TAV patients using propensity score matching (PSM) to assess the natural history of aortic root size changes. PSM is critical in this context as it balances observed covariates between BAV and TAV groups, reducing confounding bias and enhancing the accuracy of treatment effect estimates. This technique allows for valid comparisons in observational studies, addressing selection bias and leading to more reliable conclusions about the natural history of aortic root size changes post-surgery. In practice, patients with and without exposure to interest are matched on important confounding factors such as age, sex, and calendar time and compared for the incidence of outcomes [@Iwagami2022]. In such a scenario, two distinct correlations exist: the correlation between units within the matched pair and the correlation between the temporal observations on the same patient. 

The study investigators collected participant-level demographics, health outcomes, and each participant's follow-up imaging data after the replacement of the aortic valve (AVR) and ascending aorta (RAA) from January 1900 to December 2010. This cohort consists of 406 patients, 244 of whom had follow-up measurements. Among those with follow-up visits, 172 (70.5%) patients had BAV, and the rest had TAV. Our primary outcome is whether or not the aortic root dimensions exceeded a diameter of 45 mm after the surgery. Although the data include records of patients' vitals, only the follow-up measurements of the aortic root size and baseline covariates, including age, sex, and body surface area (BSA), are included in this study. 

The first consideration in GEE analysis is the potential issue of covariate endogeneity. This concept describes the scenario when the response at time $t$ predicts the covariate value at times $s > t$ [@Diggle2002]. The issue arises because the abnormal aortic root size is associated with a higher risk of death [@KITAGAWA2013258], and the occurrence of death informs that there is no stochastic process of the deformation. The interaction effect between response and covariates is called *feedback* [@Zeger1991]. It has been shown that, based on the large-sample theory, using GEE with a working independence correlation structure can provide unbiased estimation [@Diggle2002, @LiangZeger1986]. However, the sample sizes in cardiovascular research are limited and mid-term follow-ups are incomplete due to the rarity of disease in practice. The validity of GEE with a working independence correlation structure remains unknown. The second consideration is that GEE methods within the existing R package, i.e., `geepack,` only account for the correlation between repeated measurements within one subject but ignore the correlation between matched pairs. 

This report focuses on matched longitudinal binary data with covariate endogeneity and informative dropouts. We aim to explore the validity of GEE estimates for small sample matched-pair binary outcomes and compare the estimation results with the two-stage quasi-least squares (QLS) method [@Mitani2019]. In section 2, notations and assumptions are first presented, followed by a description of the issue with the correlation structure within the GEE framework, the construction of the two-stage QLS method, and the pre-processing of the motivational data. The simulation study design is presented in section 3. Section 4 presents an analysis of the motivational data and simulation results. Finally, we conclude this report with a discussion in section 5. 

## Methods 

### Notation and Assumptions 

Consider a longitudinal matched data set in which subjects are grouped into pairs, and each subject contributes repeated observations of unique aortic root diameter. Let $\boldsymbol{Y}'_{ij} = (Y_{ij1}, Y_{ij2}, ..., Y_{ijt_{ij}})$ be a vector of measurements for subject $j$ in matched pair $i$ at times $t_{ij1}, t_{ij2}, ..., t_{ijT}$, where $t_{ij1} < t_{ij2} < \cdots < t_{ijT}$; $i = 1,..., m$; $j = 1, 2$; $k = 1,...,T$. Associated with each $Y_{ijk}$ is a vector of covariates $\boldsymbol{X}'_{ijk} = (X_{ijk1}, X_{ijk2}, X_{ijk3})$ corresponding to BAV (exposure), *time*, and the interaction between BAV and *time*. Note that BAV is the exposure variable which is diagnosed before this study and does not change by time. Additionally, since  different patients may have different follow-up intervals, we define *time* as the number of visits. The outcome $Y_{ijk}$ have mean and variance 
$$
E(Y_{ijk} | X_{ijk}) = \mu_{ijk} \quad \text{and} \quad Var(Y_{ijk}) = \mu_{ijk}(1-\mu_{ijk}) = h(\mu_{ijk})
$$ 

Our analysis goal is to examine the effect of these covariates on the marginal mean of the binary outcome through $g^{-1}(\boldsymbol{X}_{ijk}'\boldsymbol{\beta})$, where $\boldsymbol{\beta} = (\beta_0, \beta_1, \beta_2,\beta_3)$ are unknown regression coefficients and $g(\cdot)$ is the invertible link function which is defined as 
$$
\begin{aligned}
g(\mu_{ijk}) &= \log(\frac{\mu_{ijk}}{1-\mu_{ijk}}) \\
&= \beta_0 + \beta_1\cdot \text{BAV}_{ijk} + \beta_2 \cdot \text{Time}_{ijk} + \beta_3\cdot (\text{BAV}_{ijk} \times \text{Time}_{ijk})\\
&= X_{ij}'\boldsymbol{\beta}.
\end{aligned}
$$

We assume that observations from different matched pairs are independent but are correlated within the same pair. The variance matrix of $\boldsymbol{Y}_i' = (Y_{i1}'. Y_{i2}')$ is given by 
$$
\Sigma_i = A_i^{1/2}(\beta) F_i(\Gamma) A_i^{1/2} (\beta) 
$$
where $F_i(\Gamma)$ is the positive definite working correlation matrix of the vector of outcome for pair $i$,  $\Gamma$ is a vector of unknown correlation parameters, and 
\begin{align}
A_i(\beta) &= \text{diag}\left\{A_{i1}(\beta), A_{i2}(\beta)\right\} \label{eq: Aibeta}\\
A_{ij}(\beta) & = \text{diag}\left\{h(\mu_{ij1}), h(\mu_{ij2}),...,h(\mu_{ijT})\right\} \label{eq: Aij}.
\end{align}

### Generalized estimating equations (GEE)

Without a specific assumption about the likelihood function, generalized estimating equations (GEE) accounts the covariance structure of the repeated measures by specifying a working correlation matrix, $R(\alpha)$, which describes the correlation between repeated measures on the same subject. This paper focuses on the following three working correlations: 
$$
\underset{\text{(Independent)}}{\begin{bmatrix}
1 & 0 & \cdots & 0\\
0 & 1 & \cdots &  0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \cdots & 1
\end{bmatrix}}
\quad
\underset{\text{(Exchangeable)}}{\begin{bmatrix}
1 & \alpha & \cdots & \alpha\\
\alpha & 1 & \cdots & \alpha\\
\vdots & \vdots & \ddots & \vdots\\
\alpha & \alpha & \cdots & 1
\end{bmatrix}}
\quad
\underset{\text{(AR1)}}{\begin{bmatrix}
1 & \alpha & \cdots & \alpha^{t_{ij} - 1}\\
\alpha & 1 & \cdots & \alpha^{t_{ij} - 2}\\
\vdots & \vdots & \ddots & \vdots\\
\alpha^{t_{ij} - 1} & \alpha^{t_{ij} - 2} & \cdots & 1
\end{bmatrix}}
$$
. The independent working correlation assumes no correlation between repeated measures. With a correlation coefficient $\alpha$, the exchangeable working correlation assumes that the correlation between any pair of repeated measurements are constant at $\alpha$, whereas the autoregressive order one (AR1) working correlation structure assumes correlation decreases exponentially with the time lag between measures. 

GEE approach accounts for overdispersion or underdispersion by correcting the variance using a dispersion parameter 
$$
\text{Var}(Y_{ijk})^* = \phi\text{Var}(Y_{ijk}) = \phi h(\mu_{ijk})
$$
Since our outcome is binary, the dispersion parameter $\phi$ equals to 1. 

The iterative process starts with initial guesses for the regression coefficients $\boldsymbol{\beta}^{(0)}$ and the correlation parameters $\alpha^{(0)}$. It is followed by the computation of initial marginal expectation $\mu_{ijk}^{(0)} = g^{-1}(X_{ijk}^T \boldsymbol{\beta}^{(0)})$, where $g^{-1}$ is the inverse of the link function. Then, the iterative process mainly consists of two steps: (1) update the working correlation matrix using the sample data. (2) update the regression coefficients. 

#### Update the Working Correlation Matrix

To update the working correlation matrix, we first compute the residuals, $r_{ijk}^{(m)} = Y_{ijk} - \mu_{ijk}^{(m)}$, based on the current estimates of the marginal means for each observation. Then, we estimate the correlation parameters using the residuals and construct the working correlation matrix $R_i^{(m)}(\alpha^{(m)})$ using the updated correlation parameters. 

#### Update the Regression Coefficients

The problem with GEE approach is that it does not account for the correlation between subjects within the same matched pair, so the variance matrix is simplified to 
\begin{equation}
\Sigma_i(\alpha) = A_i^{1/2}(\beta)R(\alpha)A_i^{1/2}(\beta) \label{eq:geeCovMat}
\end{equation}
where $A_i^{1/2}$ is defined in \eqref{eq: Aibeta}. Then, the score function and the information matrix can be calculated using the current estimates [@Zeger1988]:
\begin{align}
\boldsymbol{S}(\boldsymbol{\beta}) &= \sum_{i=1}^m D_i^T \Sigma_i^{-1}(\alpha) (Y_i - \mu_i) \label{eq:geeScoreEqs}\\
I(\boldsymbol{\beta}) &= \sum_{i=1}^m D_i^T\Sigma_i^{-1}(\alpha)D_i \label{eq:geeInfoMat}
\end{align}
where 
\begin{equation}
D_i = \frac{\partial \boldsymbol{U}_i}{\partial \boldsymbol{\beta}} = \frac{\exp(\boldsymbol{X}_i\boldsymbol{\beta})}{1+\exp(\boldsymbol{X}_i \boldsymbol{\beta})}. \label{eq:Di}
\end{equation}
The new set of regression coefficients are obtained by solving the score function, which are then used to calculate the new marginal means. 

The final estimates of the regression coefficients $\boldsymbol{\beta}$ can be obtained by repeat the above process until convergence is achieved [@Liang1986]. This iterative process ensures that the correlation structure and the regression coefficients are appropriately updated using the sample data, resulting in consistent and efficient parameter estimates in the presence of correlated repeated measures. 

However, it has been shown that the sandwich estimator tends to underestimate standard errors (SEs) when the size sample data is small [@Mitani2019]. To overcome this issue, we can adjust the sandwich estimator by degrees of freedom [@dfcorrect]:
\begin{equation}
\Sigma_{DF} = (\frac{2m}{2m-p})\Sigma \label{eq:geeSigmaDF}
\end{equation}
where $2m$ represents the number of patients, $p$ is the number of regression parameters.


### Quasi-least squares (QLS)

Quasi-least squares (QLS) is a two-stage approach for estimating the correlation parameters in the framework of generalized estimating equations (GEE). The method involves estimating the regression parameters and the correlation structure in two distinct stages. Proposed by @qls, the two-stage QLS method assumes that the covariance matrix are functions of the regression parameters and independent of the dispersion parameter $\phi$. Additionally, the off-diagonal elements are functions of some unknown nuisance parameters. The first stage mainly aims to estimate the regression parameters by minimizing the score function, which is consistent with the GEE approach. The difference is that the QLS method solves an unbiased estimating equation for $\alpha$, whereas the GEE method implements moment estimates of the correlation parameters [@qlspack]. The second stage refines the estimates of the correlation parameters based on the residuals from the first stage and updates the working correlation matrix. By iterating between these two stages, the two-stage QLS approach ensures robust and efficient estimates of the regression parameters while appropriately accounting for the correlation within the data.

This study adopted the method proposed by @Shults2002 which specified the working correlation structure by incorporating both intravisit and intrapair correlations using equicorrelated matrices and the Kronecker product. Let the working correlation parameter $\Gamma' = (\boldsymbol{\tau}', \boldsymbol{\alpha}')$ where $\boldsymbol{\tau}' = (\tau_1, ..., \tau_m)$ account for the correlation between subjects for each matched pairs and $\boldsymbol{\alpha}' = (\alpha_1, \alpha_2)$ is the vector of correlation coefficients for longitudinal measurements within the a subject in a pair. In this study, we assume that the intra-pair correlations are consistent across different pairs, that is, $\tau_1 = \tau_2 = ... = \tau_m = \tau$. Let $R_i(\boldsymbol{\alpha}) = \{r^i_{jk}(\boldsymbol{\alpha})\}$ be a $T \times T$ intravisit working correlation matrix for outcomes collected on subjects $j$ from pair $i$ and $Q_i(\tau)$ be a $2 \times 2$ equicorrelated working correlation matrix with all off-diagonal elements equal to $\tau_i$. We assume that $F_i(\Gamma)$ is the Kronecker product of $Q_i(\tau)$ and $R_i(\boldsymbol{\alpha})$, denoting as $Q_i(\tau)\otimes R_i(\boldsymbol{\alpha})$. 

Let $z_{ijk}$ be the standardized residual for the $k$-th visit on the $j$-th subject from the $i$-th pair, written as 
$$
z_{ijk} = \frac{Y_{ijk} - \mu_{ijk}}{\sqrt{h(\mu_{ijk})}}.
$$
Let $Z_{ij}'$ be a vector of standardized residuals and $U_{ij}'$ be a vector of mean values of longitudinal outcomes for the $j$-th subject form the $i$-th pair, then $Z_i'(\beta) = (Z_{i1}', Z_{i2}')$ is a vector of all standardized residuals and $\boldsymbol{U}_i' = (U_{i1}', U_{i2}')$ is a vector of all expected outcomes within $i$-th pair. Now, the generalized error sum of squares is expressed as 
$$
Q(\boldsymbol{\beta}, \boldsymbol{\Gamma}) = \sum_{i=1}^m Z_i'(\beta)F_i^{-1}(\Gamma) Z_i(\beta)
$$


#### Estimation of $\beta$ 

The estimating equation for $\boldsymbol{\beta}$ can be obtained by taking the partial derivative of $Q(\boldsymbol{\beta}, \boldsymbol{\Gamma})$ with respect to $\boldsymbol{\beta}$ and setting it equal to 0:
$$
\begin{aligned}
\frac{\partial Q(\boldsymbol{\beta}, \boldsymbol{\Gamma})}{\partial \boldsymbol{\beta}} &= 2 \sum_{i=1}^m \boldsymbol{D}_i'(\boldsymbol{\beta})F_i^{-1}(\boldsymbol{\Gamma})\boldsymbol{Z}_i(\boldsymbol{\beta})\\
&= 2\sum_{i=1}^m \boldsymbol{D}_i'(\boldsymbol{\beta})F_i^{-1}(\boldsymbol{\Gamma})\left(\frac{\boldsymbol{Y}_i - \boldsymbol{U}_i}{\sqrt{h(\boldsymbol{U}_i)}}\right)
\end{aligned}
$$
Then, we have 
\begin{equation}
\sum_{i=1}^m \boldsymbol{D}_i'(\boldsymbol{\beta})F_i^{-1}(\boldsymbol{\Gamma})\left(\frac{\boldsymbol{Y}_i - \boldsymbol{U}_i}{\sqrt{h(\boldsymbol{U}_i)}}\right) = 0, \label{eq:qlsdQdb}
\end{equation}
where $\boldsymbol{D}_i$ is defined in \eqref{eq:Di}. 

#### Estimation of $\Gamma$

The partial derivative of $Q(\boldsymbol{\beta}, \boldsymbol{\Gamma})$ with respect to $\boldsymbol{\Gamma}$ can be divided into two parts: taking partial derivative with respect to $\tau$ and $\alpha$ separately. Since the stage one estimation is is asymptotically biased [@CHAGANTY1999145], the estimation for $\tau$ and $\alpha$ involves two stages for each. 

**Stage One Estimators** 

As defined earlier, 
$$
Q_i(\tau) = 
\begin{bmatrix}
1 & \tau\\
\tau & 1
\end{bmatrix}
\implies 
Q_i^{-1}(\tau) = \frac{1}{1-\tau^2}
\begin{bmatrix}
1 & -\tau\\
-\tau & 1
\end{bmatrix}
$$
Let $q_1 = \frac{1}{1-\tau^2}$ and $q_2 = \frac{-\tau}{1-\tau^2}$, then we can obtain the first stage estimator for $\tau$ by 
\begin{align}
\frac{\partial}{\partial \tau}& \left\{
\sum_{i=1}^m 
\begin{pmatrix}
Z_{i1} & Z_{i2}
\end{pmatrix} 
\left[\begin{pmatrix}
q_1 & q_2\\
q_2 & q_1
\end{pmatrix} 
\otimes R_i^{-1}(\alpha)\right] 
\begin{pmatrix}
Z_{i1}\\ Z_{i2}
\end{pmatrix} \right\} = 0 \\
\sum_{i=1}^m &  \frac{\partial}{\partial \tau}\left[q_1(Z_{i1}R_i^{-1}Z_{i1}+Z_{i2}R_i^{-1}Z_{i2}) + 2q_2(Z_{i1}R_i^{-1}Z_{i2})\right]= 0 \label{eq:tau1}
\end{align}
Let $a_1 = (Z_{i1}R_i^{-1}Z_{i1}+Z_{i2}R_i^{-1}Z_{i2})$ and $a2 = (Z_{i1}R_i^{-1}Z_{i2})$, the stage one estimator for $\tau$ can be obtained by solving the equation \eqref{eq:tau1}:
$$
\hat{\tau}_0 = \frac{a_1 - \sqrt{a_1^2 - 4a_2^2}}{2a_2}
$$

Given that all the subjects from the motivational study underwent the aortic root replacement surgery, it is reasonable to believe that the correlation of longitudinal measurements is decreasing as time passes. Therefore, AR1 is assumed to be the true working correlation structure. Then, a closed-form solution for stage one $\alpha$ is:
\begin{equation}
\hat{\alpha}_0 = \frac{F_a + \sqrt{(F_1+F_b)(F_a-F_b)}}{F_b} \label{eq:ar1alpha1}
\end{equation}
where 
$$
F_a = \sum_{i=1}^N \frac{1}{2} \sum_{j=1}^2 \frac{1}{t_{ij}}\left[\sum_{k=1}^{t_{ij}} Z_{ijk}^T C_i^{-1} Z_{ijk} + \sum_{k=2}^{t_{ij}-1}Z_{ijk}^T C_i^{-1} Z_{ijk}\right]
$$
and 
$F_b = 2\sum_{i=1}^N \frac{1}{2}\sum_{j=1}^2\frac{1}{t_{ij}}\sum_{k=1}^{t_{ij}-1} Z_{ijk}^T C_i^{-1} Z_{ijk+1}$. The closed form solution for the stage two estimator of $\alpha$ is given by [@Mitani2019]:
\begin{equation}
\hat{\alpha} = \frac{2\hat{\alpha}_0}{1+\hat{\alpha}_0^2} \label{eq:ar1alpha2}
\end{equation}. Details of the derivations for equation \eqref{eq:ar1alpha1}is shown in the Appendix A. 

### Modeling Motivational Data 

To model the motivational data, we first selected all patients who had at least one follow-up visit with baseline measurement being taken at the day of operation. Then, a binary outcome was created by setting it to 1 if the current root size measurement is over 45 mm or the growth from the previous measure is over 5 mm, and 0 otherwise. A maximal of 6 records (including the baseline) for each patient were kept for further analysis. Then, assuming that dropouts follows Weibull distribution, 5 survival models were fitted from visit 2 to 6. The fitting coefficients were extracted for simulation. Next, a logistic regression model is fitted on the data which included the baseline measurements so that we can pair BAV patients with TAV patients using the `pairmatch` function from the R package `optmatch` [@optmatch]. Then, we applied the function `geeglm` from the R package `geepack` on the matched data set to produce the estimation results using independence, exchangeable, and AR1 working correlation structures. Finally, customized functions for implementing QLS are applied on the matched data. 

## Simulation Study 

### Full Data Simulation 

```{r, include=FALSE}
load("~/Documents/Projects/Practicum_GEE/data/realcoefs.RData")
n_patients <- 250 
n_sim <- 1500
maxT <- 6
rho <- 0.3
alpha_ci <- 0.05

gammas <- round(ps_coefs, 3)
true_coefs <- round(red_ar1$coefficients$Estimate, 3)
```


The simulation process for generating one set of cohort data involves several steps to model both covariates and binary outcomes for each patient. For each patient, we first simulated baseline covariates, including age, sex, and body surface area (BSA), by assuming a normal distribution for continuous data and a binomial distribution for binary data. To calculate the probability of having BAV, we used a logistic regression model of the form:
$$
\text{Pr}(\text{BAV} = 1 | \text{Age, Sex, BSA}) = \frac{\exp(\gamma_0 + \gamma_1 \cdot \text{Age} + \gamma_2 \cdot \text{Sex} + \gamma_3 \text{BSA})}{1+\exp(\gamma_0 + \gamma_1 \cdot \text{Age} + \gamma_2 \cdot \text{Sex} + \gamma_3 \text{BSA})}
$$
where $\gamma_0 = `r gammas[1]`, \gamma_1 = `r gammas[2]`, \gamma_2 = `r gammas[3]`$, and $\gamma_3 = `r gammas[4]`$. This probability is then used to generate the exposure variable, BAV, under binomial distribution. To simulate longitudinal matched data with binary outcomes, the marginal probability of having positive outcome is obtained by using another logistic regression model that includes BAV, visit times, and their interaction： 
$$
\text{Pr}(Y = 1 | \text{BAV, Visit, BAV} \times \text{Visit}) = \frac{\exp(\beta_0 + \beta_1 \cdot \text{BAV} + \beta_2 \cdot \text{Visit} + \beta_3 \cdot \text{BAV}\cdot \text{Visit})}{1+\exp(\beta_0 + \beta_1 \cdot \text{BAV} + \beta_2 \cdot \text{Visit} + \beta_3 \cdot \text{BAV}\cdot \text{Visit})}.
$$
where $\beta_0 = `r true_coefs[1]`, \beta_1 = `r true_coefs[2]`, \beta_2 = `r true_coefs[3]`$ and $\beta_3 = `r true_coefs[4]`$. 

Each subject is assumed to have six visits, including the baseline measurement, so six marginal probabilities are produced through this process. The true correlation among longitudinal measurements is set to be 0.3, and the working covariance is assumed to follow a first-order autoregressive structure, where correlations decrease with the distance between observations. Finally, the binary longitudinal outcomes are generated using these marginal probabilities with the `cBern` function within the `CorBin` package in R. This package, developed by @cbernWei, simulates binary outcomes by ensuring a positive definite correlation matrix and restricting the range of correlation coefficients using Prentice constraints [@Prentice1988]. 

### Informative Dropout Simulation and Propensity Score Matching

To simulate the informative dropouts, we first modeled the dropout pattern by fitting the motivational data using survival models at every visit except the baseline and the last measurement. For each visit, the status indicator was set to 1 if the maximum number of visits for the subject was the current visit, indicating dropout from the study with no further follow-up measurements. For example, the first survival model was fitted at visit 2 since visit 1 is the baseline measurement, and subjects with a total of 2 visits were assigned a status of 1. The event time was defined as the total number of visits. Given that the total number of visits was 6, four survival models were fitted to the real data. The fitting coefficients, including scale and shape parameters, were extracted from these models. These parameters were then used in the `simsurv` function to simulate dropouts at each follow-up visit for the simulated data [@simsurv20]. Once the dropout process is completed, propensity scores are calculated based on the logistic regression with the three baseline covariates, which are then been applied with the `pairmatch` function in the `optmatch` R package to match BAV subjects with TAV subjects. Then, we applied QLS with independence, AR1, and exchangeable working correlation structures to estimate the regression coefficients. We also applied GEE functions from existing R package `geepack` with the three working correlation structures [@Hojsgaard2006]. 

We simulated 1,500 data sets, each containing 250 subjects with up to 6 observations per subject, using the described simulation process. For each simulation and method, we computed the mean estimates, the mean standard errors, mean robust standard errors (MSEs), the standard deviations (SD), mean bias, and mean relative bias for each regression coefficient estimate. The mean bias was obtained by calculating the difference between the mean estimates and the respective true value, which was then divided by the true value to obtain the mean relative bias. The coverage probability was determined by calculating the proportion of the 95% confidence intervals that included the respective true parameter values among the 1,500 fitting results. 


## Results 


### Analysis of Motivational Data 

Table 1 compares the estimates, standard errors (SE), and SE adjusted for degrees of freedom (SE-DF) for the GEE and QLS methods across different working correlation structures in modeling the binary outcome of aortic root diameter in BAV patients using data from the Peter Munk Cardiac Center. A total of 22 matched pairs were successfully created using propensity score matching, resulting in a sample size of 44 patients. 

Within each method, parameter estimates are stable across correlation structures, showing minor variations. The GEE method estimates for $\beta_1$ (BAV) range from -1.093 to -1.117, while QLS estimates range from -0.108 to -0.071. For $\beta_2$ (Visit), GEE estimates range from -0.063 to -0.042, and QLS estimates range from -0.005 to 0.011. The interaction term $\beta_4$ shows a positive effect across both methods, with GEE estimates ranging from 0.192 to 0.224 and QLS estimates ranging from 0.003 to 0.026. The correlation parameter $\alpha$ are all around 0.01 and 0.55 for GEE and QLS, respectively. Specifying the working correlation to be independence is actually assuming that there is no correlation among repeated measurements, the QLS approach estimated the intra-pair correlation to be 0.494 which is higher than estimates using the other two working correlations. The intra-pair correlation is smallest when the specified working correlation is consistent with the true working correlation at around 0.307. 

Across methods, there are notable differences in parameter estimates within the same correlation structure. GEE consistently shows stronger associations for BAV status and its interaction with time compared to QLS, which yields more conservative estimates. The GEE method suggests a stronger negative association between BAV status and the binary outcome and a positive interaction effect between visit and BAV status, while the QLS method indicates smaller effects. 

```{r, include=FALSE}
library(tidyverse)
library(kableExtra)
library(ggpubr)
load("~/Documents/Projects/Practicum_GEE/Outputs/newfits_analysis.RData")
load("~/Documents/Projects/Practicum_GEE/data/se_df.RData")
source("~/Documents/Projects/Practicum_GEE/fits_analysis.R")
```


```{r motivationFit}
parameters <- c("$\\beta_0$ (Intercept)", "$\\beta_1$ (BAV)", "$\\beta_2$ (Visit)", "$\\beta_4$ (Visit $\\times$ BAV)", "$\\alpha$")
ind_df <- data.frame(est = c(coef(red_ind)$Estimate, NA, qls_ind_red$coefficients, NA, qls_ind_red$tau),
                     se = c(coef(red_ind)$Std.err, NA, qls_ind_red$se, NA, NA), 
                     se_df = c(df_se[1:4, 3], NA, df_se[13:16, 3], NA, NA))
ar1_df <- data.frame(est = c(coef(red_ar1)$Estimate, red_ar1$geese$correlation$estimate,
                             qls_ar1_red$coefficients, qls_ar1_red$alpha, qls_ar1_red$tau),
                     se = c(coef(red_ar1)$Std.err, red_ar1$geese$correlation$san.se,
                            qls_ar1_red$se, NA, NA), 
                     se_df = c(df_se[5:8, 3], NA, df_se[17:20, 3], NA, NA))
exch_df <- data.frame(est = c(coef(red_ex)$Estimate, red_ex$geese$correlation$estimate, 
                              qls_exch_red$coefficients, qls_exch_red$alpha,
                              qls_exch_red$tau),
                     se = c(coef(red_ex)$Std.err, red_ex$geese$correlation$san.se,
                            qls_exch_red$se, NA, NA), 
                     se_df = c(df_se[9:12, 3], NA, df_se[21:24, 3], NA, NA))
options(knitr.kable.NA = "")
data.frame(method = c(rep("GEE", 5), rep("QLS", 6)), 
           parameter = c(rep(parameters, 2), "$\\tau$")) %>% 
  cbind(ind_df) %>% 
  cbind(ar1_df) %>% 
  cbind(exch_df) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, escape = F,
      col.names = c("Method", "Parameter", "Estimate", "SE", "SE-DF", 
                    "Estimate", "SE", "SE-DF", "Estimate", "SE", "SE-DF"), 
      caption = "\\footnotesize Comparison of Estimations from GEE and QLS using longitudinal data from the Peter Munk Cardiac Center.") %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 6) %>% 
  kable_paper("striped", full_width = F) %>% 
  collapse_rows(columns = 1, valign = "top") %>% 
  add_header_above(c(" ", " ","Independence" = 3, "AR1" = 3, "Exchangeable" = 3)) 
```


### Simulation Results

All 1000 simulations converged for both GEE and QLS fits. Each simulation was checked for extreme values. Seventy-one simulations showed extremely large standard errors when fitted with GEE, while only nine simulations exhibited extreme standard errors using the QLS approach. These problematic simulations were removed from further analysis. Table 2 summarizes the baseline information and propensity matching results for the simulated cohort. On average, 23 out of 45 subjects had BAV, with a standard deviation (SD) of 4.577. The mean age was 55.378 years (SD: 2.098), and the average Body Surface Area (BSA) was 1.796 $m^2$ (SD: 0.060). Subjects had an average of 3 visits (SD: 0.499). The mean number of matched pairs was 23.

```{r}
cohort_analysis <- function(df, true_set){
  df %>%
    group_by(id) %>%
    slice(1) %>%
    ungroup() %>% 
    summarise(
      bav_count = sum(bav == 1, na.rm = TRUE),
      male_count = sum(male == 1, na.rm = TRUE),
      age_mean = mean(age, na.rm = TRUE),
      bsa_mean = mean(bsa, na.rm = TRUE),
      total_visit_mean = mean(total_visit, na.rm = TRUE)
    )
}
```


```{r}
load("~/Documents/Projects/Practicum_GEE/Outputs/matched_data.RData")
matched_info <- matched_df %>% 
   mutate(sim_id = 1:1500, 
         n_pairs = map_int(matched_ddat, ~ n_distinct(.x$matched)))
# Apply the function to each dataset in the list
baseline_summaries <- map_dfr(matched_info$matched_ddat, 
                              cohort_analysis, .id = "sim_id")

baseline_summaries %>% mutate(total_visit = round(total_visit_mean)) %>% 
  rename(bav = bav_count, male = male_count, age=age_mean, bsa = bsa_mean) %>% 
  select(-total_visit_mean) %>% 
  mutate(sim_id = as.numeric(sim_id)) %>% 
  left_join(matched_info %>% select(sim_id, n_pairs), by = "sim_id") %>% 
  select(-sim_id) %>% 
  summarise(mean_bav = round(mean(bav)), sd_bav = sd(bav), 
            mean_age = mean(age), sd_age = sd(age), 
            mean_bsa = mean(bsa), sd_bsa = sd(bsa), 
            mean_tv = round(mean(total_visit)), sd_tv = sd(total_visit), 
            mean_pairs = round(mean(n_pairs)), sd_pairs = sd(n_pairs), 
            mean_n = round(mean(n_pairs*2)), sd_n = sd(n_pairs*2)) %>% 
  pivot_longer(cols = everything(), 
               names_to = c(".value", "stat"),
               names_pattern = "(mean|sd)_(.*)") %>% 
  mutate(stat = case_when(stat == "bav" ~ "No.BAV", 
                          stat == "age" ~ "Age", 
                          stat == "bsa" ~ "BSA", 
                          stat == "tv" ~ "No.Total Visit", 
                          stat == "pairs" ~ "No. Pairs", 
                          stat == "n" ~ "No.Subjects")) %>% 
  rename(Term = stat, Mean = mean, SD = sd) %>% 
  kable(booktabs = TRUE, digits = 3, escape = F, 
        caption = "\\footnotesize Summary of Average Statistics Across 1500 Simulations") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
  column_spec(1, bold = T) 
```

```{r}
rm(matched_df)
```

Figure 1 shows the average regression coefficient estimates from 1000 simulations for the GEE (left three columns) and QLS (right three columns) methods. Each panel represents different coefficient estimates, with empirical standard errors (SE) displayed in the top row and SE-DF (Standard Error adjusted for degrees of freedom) in the bottom row. The mean estimates are denoted by points, and the vertical bars represent the confidence intervals. Different working correlation structures—AR1 (red), Exchangeable (blue), and Independence (green)—are compared, with the true value for each coefficient indicated by the dashed horizontal line at 0. 

In general, the mean estimates from the GEE method are more accurate compared to those from the QLS method, which tend to be biased. Both methods show difficulties in capturing the true coefficient for the effect of BAV. Specifically, the GEE method exhibits considerable variability in its estimates, while the QLS method consistently fails to capture the true value. The mean estimates for BAV using GEE are spread widely, indicating a lack of precision. In contrast, the QLS estimates, although more consistent, are systematically biased away from the true value. Additionally, there is no significant difference in the range of 95% confidence intervals between empirical SE and SE corrected by degrees of freedom, suggesting that the adjustment for degrees of freedom does not substantially impact the precision of the estimates. Additionally, the the 95% confidence intervals derived from the exchangeable correlation structure are consistently smaller than those from other structures within the QLS method. 

```{r, fig.cap="Comparison of Estimation Results From 1,500 Simulation"}
red_summary %>% 
  left_join(
    true_set %>% mutate(term = case_when(term == "visit" ~ "Visit", 
                                         term == "bav" ~ "BAV", 
                                         term == "bav:visit" ~ "BAV:Visit")), 
    by = "term") %>% 
  mutate(se = ifelse(adjusted == "Adjusted", "SE-DF", "Empirical SE")) %>% 
  rename(true_value = truth, 
         corstr = model, 
         model = type) %>% 
  mutate(term = case_when(term == "Visit" ~ "Time", 
                          term == "BAV:Visit" ~ "BAV:Time", 
                          TRUE ~ term)) %>% 
  ggplot(aes(x = corstr, y = mean_estimate, color = corstr)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, 
                position = position_dodge(width = 0.5)) +
  geom_hline(aes(yintercept = true_value), linetype = "dashed", color = "black") +
  facet_grid(se ~ model + term, scales = "free_y", 
             axes = "all", axis.labels = "all_x") +
  labs(y = "Mean Estimate",
       x = "",
       color = "Working Correlation", 
       caption = "Without adjusting for confounding covariates.") +
  scale_color_brewer(palette = "Pastel1") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "grey90"), 
        panel.grid.major.x = element_blank(), 
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        strip.placement = "outside", 
        legend.position = "bottom")
```


The relative bias of estimates for the effect of BAV across different working correlation structures (AR1, Exchangeable, Independence) using the GEE and QLS methods, with and without including confounding covariates, are presented in Figure 2. The dashed horizontal line at $y = 0$ is used as a reference to indicate 0 relative bias for estimating the BAV effect. The left panel shows the GEE method, in which the median relative bias values are close to zero across all correlation structures, although considerable variability and numerous outliers exist. In contrast, the QLS method on the right maintains consistently low variability but a systematic positive bias in the estimates. There is no significant difference between plots with and without inclusion of confounding covariates. The detailed number of outliers are reported in Appendix B. 

```{r, fig.cap="Relative bias of estimations for the effect of BAV using GEE and QLS with independence, AR1, and exchangeable working correlation structures. "}
red_relbias_df <- cal_rel_bias(gee_sim_results$ind_mdl_red, true_set) %>% 
  cbind(method = "GEE") %>% cbind(corstr = "Independence") %>% 
  rbind(cal_rel_bias(gee_sim_results$ar1_mdl_red, true_set) %>% 
          cbind(method = "GEE") %>% cbind(corstr = "AR1")) %>% 
  rbind(cal_rel_bias(gee_sim_results$exch_mdl_red, true_set) %>% 
          cbind(method = "GEE") %>% cbind(corstr = "Exchangeable")) %>% 
  rbind(cal_rel_bias(qls_sim_results$ind_mdl_red, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "Independence")) %>% 
  rbind(cal_rel_bias(qls_sim_results$ar1_mdl_red, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "AR1")) %>% 
  rbind(cal_rel_bias(qls_sim_results$exch_mdl_red, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "Exchangeable")) %>% 
  cbind(cov_set = "No")
full_relbias_df <- cal_rel_bias(gee_sim_results$ind_mdl_full, true_set) %>% 
  cbind(method = "GEE") %>% cbind(corstr = "Independence") %>% 
  rbind(cal_rel_bias(gee_sim_results$ar1_mdl_full, true_set) %>% 
          cbind(method = "GEE") %>% cbind(corstr = "AR1")) %>% 
  rbind(cal_rel_bias(gee_sim_results$exch_mdl_full, true_set) %>% 
          cbind(method = "GEE") %>% cbind(corstr = "Exchangeable")) %>% 
  rbind(cal_rel_bias(qls_sim_results$ind_mdl_full, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "Independence")) %>% 
  rbind(cal_rel_bias(qls_sim_results$ar1_mdl_full, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "AR1")) %>% 
  rbind(cal_rel_bias(qls_sim_results$exch_mdl_full, true_set) %>% 
          cbind(method = "QLS") %>% cbind(corstr = "Exchangeable")) %>% 
  cbind(cov_set = "Yes")

relbias_df <- rbind(red_relbias_df, full_relbias_df) %>% 
  relocate(c(method, corstr, cov_set), .before = b0)

relbias_df %>% select(-c(b0, b2, b3)) %>% 
  filter(b1 > -5 & b1 < 5) %>% 
  ggplot(aes(x = corstr, y = b1, color = corstr)) +
  geom_boxplot()+
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(cov_set ~ method, scales = "free_y", 
             axes = "all", axis.labels = "all_x") +
  labs(y =expression(beta[1] ~ "(BAV)"),
       x = "",
       color = "Working Correlation", 
       caption = "No = not include confounding covariates,
       Yes = include confounding covariates") +
  scale_color_brewer(palette = "Pastel1") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "grey90"), 
        panel.grid.major.x = element_blank(), 
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        strip.placement = "outside", 
        legend.position = "bottom")
```

Figure 3  illustrates the relative bias in the coefficient estimates of the interaction effect between BAV and time. With the same layout as Figure 2, the GEE method provides nearly unbiased estimates of $\beta_3$ on average but exhibits significant variability. In contrast, the QLS method produces negatively biased estimates with low variability. 

```{r, fig.cap="Relative bias of estimations for the interaction effect of BAV and time using GEE and QLS with independence, AR1, and exchangeable working correlation structures."}
relbias_df %>% select(-c(b0, b1, b2)) %>% 
  filter(b3 > -50 & b3 < 50) %>% 
  ggplot(aes(x = corstr, y = b3, color = corstr)) +
  geom_boxplot()+
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  facet_grid(cov_set ~ method, scales = "free_y", 
             axes = "all", axis.labels = "all_x") +
  labs(y =expression(beta[3] ~ "(BAV" %*% "Visit)"),
       x = "",
       color = "Working Correlation", 
       caption = "No = not include confounding covariates,
       Yes = include confounding covariates") +
  scale_color_brewer(palette = "Pastel1") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "grey90"), 
        panel.grid.major.x = element_blank(), 
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        strip.placement = "outside", 
        legend.position = "bottom")
```

The comparison of the mean estimation for correlations $\alpha$ among longitudinal measurements between GEE and QLS methods is shown in Table 2. As indicated by the column truth, the true correlation is set to be 0.3 at the simulation stage. When the working correlation is correctly specified, i.e., AR1, the GEE method exhibits a mean estimate of 0.236 with a bias of -0.064 when no covariate set is considered, and a mean estimate of 0.185 with a bias of -0.115 when covariates are included. The QLS method shows a mean estimate of 0.725 with a bias of 0.425, irrespective of covariate inclusion. On the other hand, when the working correlation is misspecified to be exchangeable, the GEE method yields a mean estimate of 0.124 with a bias of -0.176 without covariates, and a mean estimate of 0.086 with a bias of -0.214 with covariates. Meanwhile, the QLS method provides mean estimates of 0.560 and 0.723, with corresponding biases of 0.260 and 0.423, respectively.

```{r}
rho_df <- calculate_mean_rho(gee_sim_results$ar1_mdl_red) %>% 
  rbind(calculate_mean_rho(gee_sim_results$ar1_mdl_full)) %>% 
  rbind(calculate_mean_rho(gee_sim_results$exch_mdl_red)) %>% 
  rbind(calculate_mean_rho(gee_sim_results$exch_mdl_full)) %>% 
  select(mean_rho, bias) %>% 
  cbind(corstr = c(rep("AR1", 2), rep("Exchangeable", 2))) %>% 
  cbind(mod = rep(c("No", "Yes"), 2)) %>% 
  cbind(rho=0.3) %>% 
  relocate(c(corstr, mod, rho), .before = mean_rho) %>% 
  cbind(calculate_mean_rho(qls_sim_results$ar1_mdl_red) %>% 
      rbind(calculate_mean_rho(qls_sim_results$ar1_mdl_full)) %>%
      rbind(calculate_mean_rho(qls_sim_results$exch_mdl_red)) %>% 
      rbind(calculate_mean_rho(qls_sim_results$ar1_mdl_full)) %>% 
      select(mean_rho, bias))

colnames(rho_df) <- c("Working Correlation", "Covariate Set", "Truth", 
                      "Mean Estimate",  "Bias", "Mean Estimate", "Bias")


rho_df %>%
  kable(format = "latex", booktabs = TRUE, digits = 3, escape = F, 
        caption = "\\footnotesize Comparison of mean estimation for the correlation among longitudinal measurements using GEE and QLS methods, with and without adjustment for age, sex, and BSA.") %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
  column_spec(1, bold = T) %>%
  collapse_rows(columns = 1, valign = "top") %>% 
  add_header_above(c(" " = 3, "GEE" = 2, "QLS" = 2)) %>% 
  footnote(symbol = "Covariate Set: Yes = Included confounding covariates, No = Without confounding covariates",
           footnote_as_chunk = T)
```

Table 3 presents the estimation of correlations ($\tau$) between subjects in matched pairs using the QLS approach, across the three different working correlations and covariate sets (with and without confounder adjustment). In general, the differences in the intra-pair correlation estimation between models with and without confounding covariates are ignorable irrespective of the specified working correlation. When the specified working correlation matches with the true working correlation (AR1), he intra-pair correlation is estimated to be the lowest, at around 0.362, similar to the estimate based on exchangeable working correlation. However, the intra-pair correlation is estimated to around 0.5 when the working correlation is specified to be independence. 

```{r}
red_tau <- data.frame(
  ind = pull_tau(qls_sim_results$ind_mdl_red),
  ar1 = pull_tau(qls_sim_results$ar1_mdl_red),
  exch = pull_tau(qls_sim_results$exch_mdl_red)) %>% 
  cbind(covset = "No") 

full_tau <- data.frame(
  ind = pull_tau(qls_sim_results$ind_mdl_full),
  ar1 = pull_tau(qls_sim_results$ar1_mdl_full),
  exch = pull_tau(qls_sim_results$exch_mdl_full)) %>% 
  cbind(covset = "Yes")

mean_red_tau <- red_tau %>% rbind(full_tau) %>% 
  pivot_longer(!covset, names_to = "corstr", values_to = "tau") %>% 
  group_by(corstr, covset) %>% 
  summarise(mean_tau = mean(tau), 
            sd_tau = sd(tau)) %>% 
  mutate(corstr = case_when(corstr == "ar1" ~ "AR1", 
                            corstr == "ind" ~ "Independence", 
                            TRUE ~ "Exchangeable")) %>% 
  filter(covset == "No") %>% ungroup()

mean_full_tau <- red_tau %>% rbind(full_tau) %>% 
  pivot_longer(!covset, names_to = "corstr", values_to = "tau") %>% 
  group_by(corstr, covset) %>% 
  summarise(mean_tau = mean(tau), 
            sd_tau = sd(tau)) %>% 
  mutate(corstr = case_when(corstr == "ar1" ~ "AR1", 
                            corstr == "ind" ~ "Independence", 
                            TRUE ~ "Exchangeable")) %>% 
  filter(covset == "Yes") %>% ungroup()
```


```{r}
mean_red_tau %>% select(-covset) %>% 
  cbind(mean_full_tau %>% select(-corstr, -covset)) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, escape = F, 
        caption = "\\footnotesize Estimation of correlations between subjects in matched pairs using QLS approach.", 
        col.names = c("Working Correlation", rep(c("Mean $\\tau$", "SD $\\tau$"), 2))) %>% 
  kable_styling(latex_options = c("HOLD_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
  column_spec(1, bold = T) %>% 
  add_header_above(c(" " = 1, "No Confounders" = 2, "With Confounders" = 2))
```

```{r, fig.cap="Estimation of intra-pair correlation using QLS approach across three different working correlation structures for both with and without inclusion of confounding covariates. ", out.width="70%"}
tau_df %>% 
  ggplot(aes(x = corstr, y = tau, color = corstr)) +
  geom_boxplot()+
  facet_grid(~covset) +
  labs(y =expression(tau),
       x = "",
       color = "Working Correlation", 
       caption = "No = no inclusion of confounding covariates,
       Yes = with inclusion confounding covariates") +
  scale_color_brewer(palette = "Pastel1") +
  theme_classic() +
  theme(panel.grid.major = element_line(color = "grey90"), 
        panel.grid.major.x = element_blank(), 
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        strip.placement = "outside", 
        legend.position = "bottom")
```


```{r, eval=FALSE}
unajd_df <- data.frame(
  corstr = c(rep("Independence", 8), rep("AR1", 8), rep("Exchangeable", 8)), 
  type = rep(c(rep("GEE", 4), rep("QLS", 4)), 3)) %>% 
  cbind(cbind(evaluate_fits(gee_sim_results$ind_mdl_red, true_set) %>% 
                rbind(evaluate_fits(qls_sim_results$ind_mdl_red, true_set)) %>% 
                rbind(evaluate_fits(gee_sim_results$ar1_mdl_red, true_set)) %>% 
                rbind(evaluate_fits(qls_sim_results$ar1_mdl_red, true_set)) %>% 
                rbind(evaluate_fits(gee_sim_results$exch_mdl_red, true_set)) %>% 
                rbind(evaluate_fits(qls_sim_results$exch_mdl_red, true_set)) %>% 
                select(-c(bias, mse)))) %>% 
  relocate(truth, .after = term) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                          term == "bav" ~ "BAV", 
                          term == "bav:visit" ~ "BAV:Visit", 
                          term == "visit" ~ "Visit")) 

names(unajd_df)[6] <- paste0(names(unajd_df)[6], footnote_marker_symbol(1))
kable(unajd_df, format = "latex", booktabs = TRUE, digits = 3, escape = F,
      caption = "\\footnotesize Simulation results from models without adjustment for confounding covariates",
      col.names = c("Correlation", "Type", "Term", "True Value", "Mean Estimate", 
                    "SD(Estimate)", "Mean SD", "Mean DF-SE", "Mean Rel. Bias")) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
   column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>% 
  footnote(symbol = "Standard Deviation",
           symbol_title = "SD ",
           footnote_as_chunk = T)
```


```{r, eval=FALSE}
adj_df <- data.frame(
  corstr = c(rep("Independence", 8), rep("AR1", 8), rep("Exchangeable", 8)), 
  type = rep(c(rep("GEE", 4), rep("QLS", 4)), 3)) %>% 
  cbind(cbind(evaluate_fits(gee_sim_results$ind_mdl_full, true_set) %>% 
                rbind(evaluate_fits(qls_sim_results$ind_mdl_full, true_set)) %>% 
                rbind(evaluate_fits(gee_sim_results$ar1_mdl_full, true_set)) %>% 
                rbind(evaluate_fits(qls_sim_results$ar1_mdl_full, true_set)) %>% 
                rbind(evaluate_fits(gee_sim_results$exch_mdl_full, true_set)) %>% 
                rbind(evaluate_fits(qls_sim_results$exch_mdl_full, true_set)) %>% 
                filter(term %in% c("(Intercept)", "bav", "bav:visit", "visit")))) %>% 
  relocate(truth, .after = term) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                          term == "bav" ~ "BAV", 
                          term == "bav:visit" ~ "BAV:Visit", 
                          term == "visit" ~ "Visit")) 

names(adj_df)[6] <- paste0(names(adj_df)[6], footnote_marker_symbol(1))
kable(adj_df, format = "latex", booktabs = TRUE, digits = 3, escape = F,
      caption = "//footnotesize Simulation results from models adjusted for confounding covariates",
      col.names = c("Correlation", "Type", "Term", "True Value", "Mean Estimate", 
                    "SD(Estimate)", "Mean SD", "Relative Bias")) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
   column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>% 
  footnote(symbol = "Standard Deviation and Mean Squared Error",
           symbol_title = "SD and MSE: ",
           footnote_as_chunk = T)
```

## Discusssion

In this study, we compared the performance of the GEE and QLS methods in modelling binary outcomes of aortic root diameter in patients with bicuspid aortic valves (BAV) versus tricuspid aortic valves (TAV). Both methods were evaluated across different working correlation structures. Our findings indicate that, within this small sample context (20 to 25 matched pairs), the GEE method shows considerable variability in its estimates, whereas the QLS method, although more consistent, exhibits systematic positive bias. The choice of working correlation structure significantly impacts the parameter estimates. The AR1 structure provided more accurate estimates in GEE because it aligns with the true working correlation used in simulating the data.

In our simulation study, we noticed that the GEE method tended to be unstable with small sample sizes, leading to variability in the estimates. On the other hand, the QLS method provided more consistent results, but these were often biased. This means that QLS might either underestimate or overestimate the true effects because of how it deals with the correlation structure. Interestingly, even though we tested different working correlation structures (AR1, exchangeable, and independence), the parameter estimates for each method didn't change much. This suggests that for small matched samples, the specific choice of correlation structure might not significantly affect the overall estimates for binary outcomes. However, it’s still crucial to choose the right correlation structure to ensure accurate standard errors and confidence intervals.

In the clinical context of aortic root diameter changes in BAV patients post-surgery, the methodological differences between GEE and QLS can influence clinical decision-making. Accurate modelling of aortic root changes is crucial for assessing the risk of aortic dilatation and planning follow-up care. As shown in Figure 1, the true effect of BAV is estimated to be around -1. However, the QLS method provides an average estimate of around 0, indicating a substantial positive bias. As a comparison, although with more variability, the GEE method offers more conservative and closer-to-true estimates for the effect of BAV and its interaction with time. These estimation differences can have important implications for clinical decisions. Overestimating the effect of interventions or conditions like BAV due to biased estimates from QLS may lead to inappropriate clinical strategies. On the other hand, the variability in GEE estimates requires careful interpretation to avoid misjudging the treatment effect.

It's important to note several limitations. While using simulated data allows for controlled studies, it might not fully reflect the complexities of real-world data. Both GEE and QLS methods have limitations in handling informative dropouts and covariate endogeneity, which could affect the robustness of the estimates. The small sample size poses challenges for the GEE method, potentially leading to underestimated standard errors and variability in estimates. The informative dropout process modelled in our simulations may not fully capture real-world complexities. However, it also presents an opportunity for further investigations to refine GEE and QLS approaches for handling informative dropouts and covariate endogeneity in longitudinal studies.

In conclusion, our comparative analysis of GEE and QLS methods underscores the importance of methodological considerations in longitudinal data analysis. While GEE showed a better ability to capture the correlation among repeated measurements, QLS demonstrated lower variability and consistent parameter estimates across different correlation structures. These robust findings offer confident guidance for researchers in selecting appropriate analytical approaches for their studies, reinforcing the importance of methodological considerations in longitudinal data analysis.


\newpage 

## Appendix A

### Estimation for Stage One $\alpha$

Since the maximum number repeated measurement within the same subject is restricted to 6, we take $t_{ij} = 4$ as an example for simplicity. The intravisit correlation structure is 
$$
R_i(\alpha) = 
\begin{bmatrix}
1 & \alpha & \alpha^2 & \alpha^3\\
\alpha & 1 & \alpha & \alpha^2\\
\alpha^2 & \alpha & 1 & \alpha\\
\alpha^3 & \alpha^2 & \alpha & 1
\end{bmatrix}
$$
The partial derivative of covariance matrix with respect to $\alpha$ is 
$$
\frac{\partial F_i^{-1}(\alpha)}{\partial \alpha} = \frac{\partial{R_i^{-1}(\alpha)}}{\partial \alpha} \otimes Q_i^{-1}(\tau)
$$
because $Q^{-1}_i(\tau)$ does not contain $\alpha$. 
$$
\frac{\partial{R_i^{-1}(\alpha)}}{\partial \alpha} = -R_i^{-1}(\alpha) \frac{\partial R_i(\alpha)}{\partial \alpha} R_i^{-1}(\alpha)
$$

$$
\frac{\partial R_i(\alpha)}{\partial \alpha}= 
\begin{bmatrix}
0 & 1 & 2\alpha & 3\alpha^2\\
1 & 0 & 1 & 2\alpha\\
2\alpha & 1 & 0 & 1\\
3\alpha^2 & 2\alpha & 1 & 0
\end{bmatrix}
$$
Therefore, 
$$
\frac{\partial{R_i^{-1}(\alpha)}}{\partial \alpha}= 
\frac{1}{(1-\alpha^2)^2}
\begin{bmatrix}
2\alpha & -(1+\alpha^2) & 0 & 0\\
-(1+\alpha^2) & 4\alpha & -(1+\alpha^2) & 0\\
0 & -(1+\alpha^2) & 4\alpha & -(1+\alpha^2)\\
0 & 0 & -(1+\alpha^2) & 0
\end{bmatrix}
$$
$$
\frac{\partial{R_i^{-1}(\alpha)}}{\partial \alpha}\otimes Q_i^{-1} = 
\frac{1}{(1-\alpha^2)^2}
\begin{bmatrix}
2\alpha Q_i^{-1} & -(1+\alpha^2) Q_i^{-1} & 0 & 0\\
-(1+\alpha^2) Q_i^{-1} & 4\alpha Q_i^{-1} & -(1+\alpha^2) Q_i^{-1} & 0\\
0 & -(1+\alpha^2) Q_i^{-1} & 4\alpha Q_i^{-1} & -(1+\alpha^2) Q_i^{-1}\\
0 & 0 & -(1+\alpha^2) Q_i^{-1} & 2\alpha Q_i^{-1}
\end{bmatrix}
$$
Hence, 
$$
\begin{aligned}
\frac{\partial Q(\beta, \Gamma)}{\partial \alpha} &= 
\sum_{i=1}^m \sum_{j=1}^2 
\begin{pmatrix}
Z_{i1} & Z_{i2} & Z_{i3} & Z_{i4} 
\end{pmatrix}
\frac{\partial{R_i^{-1}(\alpha)}}{\partial \alpha}\otimes Q_i^{-1}
\begin{pmatrix}
Z_{i1} \\ Z_{i2} \\ Z_{i3} \\ Z_{i4} 
\end{pmatrix}\\
&= \frac{1}{(1-\alpha^2)^2} \sum_{i=1}^m \sum_{j=1}^2 
\Big\{2\alpha \Big(Z_{ij1}Q_i^{-1}Z_{ij1} + 2Z_{ij2}Q_i^{-1}Z_{ij2}+  2Z_{ij3}Q_i^{-1}Z_{ij3}+Z_{ij4}Q_i^{-1}Z_{ij4}\Big)\\
& \quad \quad \quad \quad \quad\quad 2(1+\alpha^2)\cdot 
\Big(Z_{ij1}Q_i^{-1}Z_{ij2}+Z_{ij2}Q_i^{-1}Z_{ij3}+Z_{ij3}Q_i^{-1}Z_{ij4}\Big)
\Big\}\\
&= \sum_{i=1}^m \sum_{j=1}^2 \left\{\alpha 
\left(\sum_{k=1}^{t_{ij}} Z_{ijk}'Q_i^{-1} Z_{ijk} + \sum_{k=2}^{t_{ij} - 1}Z_{ijk}'Q_i^{-1} Z_{ijk}\right) - (1+\alpha^2)\left(\sum_{k=1}^{t_{ij} - 1}Z_{ijk}'Q_i^{-1}Z_{ijk+1}\right) \right\}
\end{aligned}
$$
Let $S_1 = \sum_{k=1}^{t_{ij}} Z_{ijk}'Q_i^{-1} Z_{ijk} + \sum_{k=2}^{t_{ij} - 1}Z_{ijk}'Q_i^{-1} Z_{ijk}$ and $S_2 = \sum_{k=1}^{t_{ij} - 1}Z_{ijk}'Q_i^{-1}Z_{ijk+1}$, 
then 
$$
\begin{aligned}
\frac{\partial Q(\beta, \Gamma)}{\partial \alpha} &= \sum_{i=1}^m \sum_{j=1}^2 \big(\alpha S_1 - (1+\alpha^2) S_2\big) \\
&= \sum_{i=1}^m \sum_{j=1}^2\big(\alpha S_1 - S_2-\alpha^2S_2\big) = 0\\
& \sum_{i=1}^m \sum_{j=1}^2\big(\alpha^2 S_2 -\alpha S_1 + S_2\big) = 0\\
\hat{\alpha}_0 &= \sum_{i=1}^m \sum_{j=1}^2\frac{S_1+\sqrt{S_1^2+4S_2^2}}{2S_2}
\end{aligned}
$$

\newpage
## Appendix B

### Coverage Probability 

```{r}
# GEE 
# (1) Coverage probabilities for models without adjustment by age, male, and BSA
coverage_gee_unadj <- calculate_coverage(gee_sim_results$ind_mdl_red, true_set) %>%
  rbind(calculate_coverage(gee_sim_results$ar1_mdl_red, true_set)) %>%
  rbind(calculate_coverage(gee_sim_results$exch_mdl_red, true_set)) %>%
  na.omit()

# (2) Coverage probabilities for models adjusted by age, male, and BSA
coverage_gee_adj <- calculate_coverage(gee_sim_results$ind_mdl_full, true_set) %>%
  rbind(calculate_coverage(gee_sim_results$ar1_mdl_full, true_set)) %>%
  rbind(calculate_coverage(gee_sim_results$exch_mdl_full, true_set)) %>%
  na.omit()

# QLS
# (1) Coverage probabilities for models without adjustment by age, male, and BSA
coverage_qls_unadj <- calculate_coverage(qls_sim_results$ind_mdl_red, true_set) %>%
  rbind(calculate_coverage(qls_sim_results$ar1_mdl_red, true_set)) %>%
  rbind(calculate_coverage(qls_sim_results$exch_mdl_red, true_set)) %>%
  na.omit()

# (2) Coverage probabilities for models adjusted by age, male, and BSA
coverage_qls_adj <- calculate_coverage(qls_sim_results$ind_mdl_full, true_set) %>%
  rbind(calculate_coverage(qls_sim_results$ar1_mdl_full, true_set)) %>%
  rbind(calculate_coverage(qls_sim_results$exch_mdl_full, true_set)) %>%
  na.omit()

coverage_gee_adj %>% cbind(coverage_gee_unadj %>% select(-term)) %>%
  cbind(coverage_qls_unadj %>% select(-term)) %>% 
  cbind(coverage_qls_adj %>% select(-term)) %>% 
  cbind(corstr = c(rep("Independence", 4), rep("AR1", 4), rep("Exchangeable", 4))) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, escape = F, 
        caption = "\\footnotesize The Coverage Probability of Regression Coefficient Estimation from GEE and QLS.", 
        col.names = c("Corstr", "Term", rep(c("Empirical SE", "DF-SE"),4))) %>% 
  kable_styling(latex_options = c("hold_position", "scale_down"), font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
  add_header_above(c(" " = 2, "No Confounders" = 2, "With Confounders" = 2, 
                     "No Confounders" = 2, "With Confounders" = 2)) %>% 
  add_header_above(c(" " = 2, "GEE" = 4, "QLS" = 4))
```

### Simulation Results

```{r}
adj_ar1 <- data.frame(corstr = rep("AR1", 14),
           type = c(rep("GEE", 7), rep("QLS", 7))) %>% 
  cbind(evaluate_fits(gee_sim_results$ar1_mdl_full, true_set) %>% 
           rbind(evaluate_fits(qls_sim_results$ar1_mdl_full, true_set))) %>% 
  na.omit() %>% 
  relocate(truth, .after = term) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                          term == "bav" ~ "BAV", 
                          term == "bav:visit" ~ "BAV:Visit", 
                          term == "visit" ~ "Visit")) %>% 
  select(-mean_bias, -mean_rel_bias)

rownames(adj_ar1) <- NULL
names(adj_ar1)[1] <- paste0(names(adj_ar1)[1], footnote_marker_symbol(1))

kable(adj_ar1, format = "latex", booktabs = TRUE, digits = 3, escape = F,
      col.names = c("Corstr", "Type", "Term", "True Value", "Mean Est", 
                    "SD Est", "Mean SE", "Mean SE-DF", "Mean MSE")) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
   column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>% 
  footnote(symbol = "Correlation Structure",
           symbol_title = "Corstr: ",
           footnote_as_chunk = T)
```


```{r}
adj_exch <- data.frame(corstr = rep("Exchangeable", 14),
           type = c(rep("GEE", 7), rep("QLS", 7))) %>% 
  cbind(evaluate_fits(gee_sim_results$exch_mdl_full, true_set) %>% 
           rbind(evaluate_fits(qls_sim_results$exch_mdl_full, true_set))) %>% 
  na.omit() %>% 
  relocate(truth, .after = term) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                          term == "bav" ~ "BAV", 
                          term == "bav:visit" ~ "BAV:Visit", 
                          term == "visit" ~ "Visit")) %>% 
  select(-mean_bias, -mean_rel_bias)

rownames(adj_exch) <- NULL
names(adj_exch)[1] <- paste0(names(adj_exch)[1], footnote_marker_symbol(1))

kable(adj_exch, format = "latex", booktabs = TRUE, digits = 3, escape = F,
      col.names = c("Corstr", "Type", "Term", "True Value", "Mean Est", 
                    "SD Est", "Mean SE", "Mean SE-DF", "Mean MSE")) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
   column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>% 
  footnote(symbol = "Correlation Structure",
           symbol_title = "Corstr:",
           footnote_as_chunk = T)
```

```{r}
adj_ind <- data.frame(corstr = rep("Independence", 14),
           type = c(rep("GEE", 7), rep("QLS", 7))) %>% 
  cbind(evaluate_fits(gee_sim_results$ind_mdl_full, true_set) %>% 
           rbind(evaluate_fits(qls_sim_results$ind_mdl_full, true_set))) %>% 
  na.omit() %>% 
  relocate(truth, .after = term) %>% 
  mutate(term = case_when(term == "(Intercept)" ~ "Intercept", 
                          term == "bav" ~ "BAV", 
                          term == "bav:visit" ~ "BAV:Visit", 
                          term == "visit" ~ "Visit")) %>% 
  select(-mean_bias, -mean_rel_bias)

rownames(adj_ind) <- NULL
names(adj_ind)[1] <- paste0(names(adj_ind)[1], footnote_marker_symbol(1))

kable(adj_ind, format = "latex", booktabs = TRUE, digits = 3, escape = F,
      col.names = c("Corstr", "Type", "Term", "True Value", "Mean Est", 
                    "SD Est", "Mean SE", "Mean SE-DF", "Mean MSE")) %>%
  kable_styling(latex_options = c("hold_position", "scale_down"), 
                font_size = 8) %>% 
  kable_paper("striped", full_width = F) %>% 
   column_spec(1, bold = T) %>%
  collapse_rows(columns = 1:2, valign = "top") %>% 
  footnote(symbol = "Correlation Structure, Standard Deviation and Mean Squared Error",
           symbol_title = "Corstr, SD, MSE: ",
           footnote_as_chunk = T)
```


### Outliers in Relative Bias 

**BAV**

```{r}
bav_outliers_df <- relbias_df %>%
  select(-c(b0, b2, b3)) %>%
  group_by(corstr, cov_set, method) %>%
  summarise(Q1 = quantile(b1, 0.25), Q3 = quantile(b1, 0.75)) %>%
  mutate(IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR)

bav_outliers <- relbias_df %>%
  select(-c(b0, b2, b3)) %>%
  left_join(bav_outliers_df, by = c("corstr", "cov_set", "method")) %>%
  filter(b1 < lower_bound | b1 > upper_bound) %>%
  select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)

bav_outliers %>% 
  group_by(method, corstr, cov_set) %>% 
  summarise(n = n()) %>% 
  arrange(n) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, 
        col.names = c("Method", "Working Correlation", 
                      "Confounders", "No.Outliers"), 
        caption = "Outliers in Relative Bias for the effect of BAV") %>% 
  kable_paper("striped", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  collapse_rows(columns = 1:2, valign = "top") 
```


**Time**
```{r}
visit_outliers_df <- relbias_df %>%
  select(-c(b0, b1, b3)) %>%
  group_by(corstr, cov_set, method) %>%
  summarise(Q1 = quantile(b2, 0.25), Q3 = quantile(b2, 0.75)) %>%
  mutate(IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR)

visit_outliers <- relbias_df %>%
  select(-c(b0, b1, b3)) %>%
  left_join(visit_outliers_df, by = c("corstr", "cov_set", "method")) %>%
  filter(b2 < lower_bound | b2 > upper_bound) %>%
  select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)


visit_outliers %>% 
  group_by(method, corstr, cov_set) %>% 
  summarise(n = n()) %>% 
  arrange(n) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, 
        col.names = c("Method", "Working Correlation", 
                      "Confounders", "No.Outliers"), 
        caption = "Outliers in Relative Bias for the effect of Time") %>% 
  kable_paper("striped", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  collapse_rows(columns = 1:2, valign = "top") 
```

**Interaction Effect between BAV and Time** 

```{r}
interaction_outliers_df <- relbias_df %>%
  select(-c(b0, b1, b2)) %>%
  group_by(corstr, cov_set, method) %>%
  summarise(Q1 = quantile(b3, 0.25), Q3 = quantile(b3, 0.75)) %>%
  mutate(IQR = Q3 - Q1,
         lower_bound = Q1 - 1.5 * IQR,
         upper_bound = Q3 + 1.5 * IQR)

interaction_outliers <- relbias_df %>%
  select(-c(b0, b1, b2)) %>%
  left_join(interaction_outliers_df, by = c("corstr", "cov_set", "method")) %>%
  filter(b3 < lower_bound | b3 > upper_bound) %>%
  select(-Q1, -Q3, -IQR, -lower_bound, -upper_bound)


interaction_outliers %>% 
  group_by(method, corstr, cov_set) %>% 
  summarise(n = n()) %>% 
  arrange(n) %>% 
  kable(format = "latex", booktabs = TRUE, digits = 3, 
        col.names = c("Method", "Working Correlation", 
                      "Confounders", "No.Outliers"), 
        caption = "Outliers in Relative Bias for the interaction effect between BAV and Time") %>% 
  kable_paper("striped", full_width = F) %>% 
  kable_styling(latex_options = "HOLD_position") %>% 
  collapse_rows(columns = 1:2, valign = "top") 
```

\newpage
