---
title: "Weekly update"
output: html_document
date: "2022-11-15"
---

## Nov 14-18, 2022
### Meeting on Nov 15
* GitHub setup, cloned repository
* Discussed about project background and details
* Discussed next steps
  + prepare for the presentation
  + review *Applied Longitudinal Analysis* (Chapter 11-13)
* Q&A:
  + What's the difference between GEE and GLMM?
    - The interpretation of the parameters is different. The target of inference of GEE is population-average, whereas the GLMM is subject-specific.
    
### Accomplishment
1. Literature Review
a) Propensity Score methods
b) Generalized Estimating Equations (GEE)
c) Time-dependent Covariates (12.1-12.3)
d) Cardiovascular research
  * Improved Outcomes Following the Ross Procedure Compared With Bioprosthetic Aortic Valve Replacement
e) review Generalized linear model
  
2. Presentation slides (draft)

3. On-boarding process
* completed the UHN Office of Research Trainee(ORT) e-registration form
* returned a signed offer of appointment, Personal Data and Emergency Contact Form and documents from the part A of appendix A(passport & study permit)
* Start date: December 5, 2022
* Orientation: Tuesday, December 13, 2022

### Questions
1. Why GEE with independent working correlation is used for unbiased estimation when the follow-up data is *truncated by death*?
- censoring: assume independent, missing not at random
- GEE: assume missing completely at random. 
- Inverse probability weighting: dealing with drop-out due to death
- For this practicum, assume we don't have missing data.
2. What is the purpose of simulations before using the real data for this study?
- Logistic problem: we don't have the data yet
- Need real data to design the simulation study and decide what parameter we're going to use. We want the simulated data as close as the real data. We'll use the real data to do analysis(application/illustration), but won't use it to make any new scientific discoveries.
3. How  do we include two correlation matrices for the matched pairs and the longitudinal responses while performing GEE?
4. What is the robust sandwich estimator? 
- solved: section 13.2 from Applied Longitudinal Analysis, 
$Cov(\hat{\beta}) = B^{-1}MB^{-1}$
- can obtain valid standard error for $\hat{\beta}$ under the misspecified model for the within-subject association, with large sample sizes
- robust sandwich estimator VS model-based estimator: generally use the robust sandwich estimator, almost never use the other one (unless if we are sure the correlation structure is correcly specified)


## Nov 21-25, 2022
### Meeting on Nov 22
* Discussed questions that I had from last week
* Modified presentation slides
* Discussed next steps:
  + read case studies in Chapter 13
  + use Arthritis Clinical Trial data to perform GEE 

### Accomplishment
* Presentation preparation

* Arthritis Clinical Trial example:
  + transformed the data into long format using "pivot_longer"
  + follow the sample code and fit a marginal proportional odds(ordinal) regression model with independent working correlation matrix
  + dichotomize the response variable, and fit a Marginal Logistic Regression Model with independent working correlation matrix
  
* On-boarding process:
  + UHN network account access information(TID): t119634uhn
  + Employee ID: 538335
  + UHN email address: Peiyu.Li@uhn.ca
  + Pick up computer on December 8
  
### Questions
1. In the case study Arthritis Clinical Trial in Chapter 13:
  a) Why the model used square-root transformation for time(month)?
    + month(0,2,4,6) --> (0,1.4,2,2,45), after square-root transformation, the difference is getting smaller as time increases. Instead of assuming linear effect, we assume the difference on treatment effect is largest for the first visit, and smallest for the last visit.
  b) When I changed the correlation structure in the model from independent to unstructured, the estimates in the output became "NaN". What other changes I should make to avoid this issue?
    + probably because different R version
    
2. Dichotomous response variable:
  Why the sample code uses *ordgee()* function with logit link to fit both Marginal Logistic Regression Model and Marginal Proportional Odds (Ordinal) Regression Model? Since the interpretation of the parameters is quite different for these two models.
  geeglm() gives same result as ordgee() with logit link. Are there any differences in using these two functions?
   + $\alpha$ in ordgee() output provides estimate of the *odds ratio parameter*.
   + $\alpha$ in geeglm() output provides estimate of the *correlation parameters*, and $-1 \leq \alpha \leq 1$.

  
  
## Nov 28 - Dec 02, 2022
### Meeting on Nov 29
1. R function options:
  - waves: Variable specifying the ordering of repeated measurements on the same unit (tells R the dimension of correlation matrix). Also used in connection with missing values. 
  - scale.fix: If true, it's fix at the value of 'scale.value'(by default at 1) rather than estimated. Scale is 1 for logistic regression.
2. Next steps:
  - Use arthritis dataset (303 individuals), compare parameter coefficients, standard errors, and QIC for each model using different correlation structure.
  - Randomly select 50 and 20 individuals, do the comparison again.
  
### Accomplishment

* End of term presentation on Dec 1
* Completed Health Services mandatory immunization requirements
* Completed UHN mandatory trainings

## Dec 05 - Dev 09, 2022
### No Meeting (Exam Week)
### Accomplishement

* Picked up computer, met with Kate and Sudip
* UHN orientation
* Made comparison tables for different GEE regressions using four correlation structures and different sample sizes.

### Questions

1. If the numbers of repeated measurements are not the same (e.g. contain missing values), how can we specify "waves" parameter in geeglm()? Should I specify "waves" parameter as a list of numbers of observations for each subject?

2. a) When should we set scale.fix to be false and allow the scale to be estimated from the data? 
 b) Does scale.fix=FALSE provide more efficient and accurate estimates of the regression coefficients? 
 c) Why the scale parameter becomes 1.01 instead of 1 when only included 20 subjects?
  + When using the geeglm() function in R with a small sample size and scale.fix=TRUE, the estimated scale parameter may not be exactly equal to 1. 

3. I used geepack::geeglm function for the comparison, and we can directly use QIC function. However, gee:gee function can provide both naive standard errors and robust standard error, and we can also get estimated correlation structure matrix in the summary output for gee() function. 

4. How to interpret the results based on the comparisons?
* The effect of 'sqrtmonth' became insignificant when the sample size decreased
* standard errors for time-related variables increased as the sample size decreased.
* QIC for different correlation structured were almost the same for a given sample size, but QIC decreased as the sample size decreased.

5. For propensity score matching, do we need to consider caliper distance when performing the matching?

## Dec 12 - Dec 16, 2022
### Meeting on Dec13
















  